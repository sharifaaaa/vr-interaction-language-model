# VR Interaction as a Language-Like Sequence

This repository contains code for modeling embodied interaction in Virtual Reality (VR) as
language-like sequential data, using Transformer-based architectures.

## Project Motivation

Human behavior in immersive environments unfolds over time through interaction.
This project explores whether embodied VR interaction logs (gaze, motion, actions)
can be treated as structured sequences, analogous to natural language, for downstream
tasks such as emotion inference and cognitive state modeling.

## Repository Structure

\## Repository Structure



vr\_transformer/        # Transformer models for VR interaction

config\_\*.py            # Experiment configurations

classifier\_runner.py   # Model training and evaluation



